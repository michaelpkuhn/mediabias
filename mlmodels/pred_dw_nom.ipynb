{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Herman D\n",
      "[nltk_data]     Schaumburg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Herman D\n",
      "[nltk_data]     Schaumburg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from joblib import load\n",
    "# Tools to remove stopwords from tweets\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load R or D predictor\n",
    "bigram_vectorizer = load('data_preprocessors/bigram_vectorizer.joblib')\n",
    "bigram_tf_idf_transformer = load('data_preprocessors/bigram_tf_idf_transformer.joblib')\n",
    "bigram_vectorizer = load('data_preprocessors/bigram_vectorizer.joblib')\n",
    "bigram_tf_idf_transformer = load('data_preprocessors/bigram_tf_idf_transformer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def fix_party_code(pc):\n",
    "    if pc == 100:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'R'\n",
    "#    return int(pc/100-1)\n",
    "def list_tostring(input_list):\n",
    "    return ' '.join(input_list)\n",
    "\n",
    "def remove_stopwords(input_list):\n",
    "    return [w for w in input_list if not w in stop_words]\n",
    "\n",
    "def clean_tweets(input_df):\n",
    "    input_df['party_code'] = input_df['party_code'].apply(fix_party_code)\n",
    "    input_df['text'] = input_df['text'].apply(word_tokenize)\n",
    "    input_df['text'] = input_df['text'].apply(remove_stopwords)\n",
    "    input_df['text'] = input_df['text'].apply(list_tostring)    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>chamber</th>\n",
       "      <th>icpsr</th>\n",
       "      <th>state_icpsr</th>\n",
       "      <th>district_code</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>party_code</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>last_means</th>\n",
       "      <th>bioname</th>\n",
       "      <th>...</th>\n",
       "      <th>died</th>\n",
       "      <th>nominate_dim1</th>\n",
       "      <th>nominate_dim2</th>\n",
       "      <th>nominate_log_likelihood</th>\n",
       "      <th>nominate_geo_mean_probability</th>\n",
       "      <th>nominate_number_of_votes</th>\n",
       "      <th>nominate_number_of_errors</th>\n",
       "      <th>conditional</th>\n",
       "      <th>nokken_poole_dim1</th>\n",
       "      <th>nokken_poole_dim2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>House</td>\n",
       "      <td>20301</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ROGERS, Mike Dennis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-157.12696</td>\n",
       "      <td>0.78556</td>\n",
       "      <td>651</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>House</td>\n",
       "      <td>21102</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>AL</td>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SEWELL, Terri</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-26.01682</td>\n",
       "      <td>0.96146</td>\n",
       "      <td>662</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116</td>\n",
       "      <td>House</td>\n",
       "      <td>21192</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ROBY, Martha</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-86.62113</td>\n",
       "      <td>0.87433</td>\n",
       "      <td>645</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>House</td>\n",
       "      <td>21193</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>BROOKS, Mo</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-124.80360</td>\n",
       "      <td>0.83187</td>\n",
       "      <td>678</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786</td>\n",
       "      <td>-0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>House</td>\n",
       "      <td>21376</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>BYRNE, Bradley</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-101.01760</td>\n",
       "      <td>0.84830</td>\n",
       "      <td>614</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress chamber  icpsr  state_icpsr  district_code state_abbrev  \\\n",
       "0       116   House  20301           41              3           AL   \n",
       "1       116   House  21102           41              7           AL   \n",
       "2       116   House  21192           41              2           AL   \n",
       "3       116   House  21193           41              5           AL   \n",
       "4       116   House  21376           41              1           AL   \n",
       "\n",
       "   party_code occupancy last_means              bioname  ... died  \\\n",
       "0         200                       ROGERS, Mike Dennis  ...  NaN   \n",
       "1         100                             SEWELL, Terri  ...  NaN   \n",
       "2         200                              ROBY, Martha  ...  NaN   \n",
       "3         200                                BROOKS, Mo  ...  NaN   \n",
       "4         200                            BYRNE, Bradley  ...  NaN   \n",
       "\n",
       "   nominate_dim1  nominate_dim2  nominate_log_likelihood  \\\n",
       "0          0.353          0.459               -157.12696   \n",
       "1         -0.391          0.402                -26.01682   \n",
       "2          0.361          0.656                -86.62113   \n",
       "3          0.647         -0.446               -124.80360   \n",
       "4          0.611          0.244               -101.01760   \n",
       "\n",
       "   nominate_geo_mean_probability  nominate_number_of_votes  \\\n",
       "0                        0.78556                       651   \n",
       "1                        0.96146                       662   \n",
       "2                        0.87433                       645   \n",
       "3                        0.83187                       678   \n",
       "4                        0.84830                       614   \n",
       "\n",
       "   nominate_number_of_errors conditional nokken_poole_dim1  nokken_poole_dim2  \n",
       "0                         64         NaN             0.520              0.347  \n",
       "1                         11         NaN            -0.435              0.395  \n",
       "2                         30         NaN             0.341              0.673  \n",
       "3                         50         NaN             0.786             -0.368  \n",
       "4                         40         NaN             0.707              0.167  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_df = pd.read_json(\"HS116_members.json\")\n",
    "congress_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>bioguide_id</th>\n",
       "      <th>mem_name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>chamber</th>\n",
       "      <th>state_abbr</th>\n",
       "      <th>party_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37007274</td>\n",
       "      <td>Y000033</td>\n",
       "      <td>Don Young</td>\n",
       "      <td>repdonyoung</td>\n",
       "      <td>House</td>\n",
       "      <td>AK</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2559398984</td>\n",
       "      <td>Y000033</td>\n",
       "      <td>Don Young</td>\n",
       "      <td>DonYoungAK</td>\n",
       "      <td>House</td>\n",
       "      <td>AK</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2253968388</td>\n",
       "      <td>B001289</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "      <td>RepByrne</td>\n",
       "      <td>House</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42481696</td>\n",
       "      <td>B001289</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "      <td>BradleyByrne</td>\n",
       "      <td>House</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2861616083</td>\n",
       "      <td>P000609</td>\n",
       "      <td>Gary Palmer</td>\n",
       "      <td>USRepGaryPalmer</td>\n",
       "      <td>House</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id bioguide_id       mem_name      screen_name chamber state_abbr  \\\n",
       "0    37007274     Y000033      Don Young      repdonyoung   House         AK   \n",
       "1  2559398984     Y000033      Don Young       DonYoungAK   House         AK   \n",
       "2  2253968388     B001289  Bradley Byrne         RepByrne   House         AL   \n",
       "3    42481696     B001289  Bradley Byrne     BradleyByrne   House         AL   \n",
       "4  2861616083     P000609    Gary Palmer  USRepGaryPalmer   House         AL   \n",
       "\n",
       "   party_code  \n",
       "0         200  \n",
       "1         200  \n",
       "2         200  \n",
       "3         200  \n",
       "4         200  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_code_df = pd.read_csv(\"partycode.csv\")\n",
    "party_code_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify congresspeople by their twitter IDs\n",
    "twit_congress_df = congress_df.merge(party_code_df[['bioguide_id','account_id','mem_name']], how = 'right', left_on='bioguide_id', right_on='bioguide_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>chamber</th>\n",
       "      <th>icpsr</th>\n",
       "      <th>state_icpsr</th>\n",
       "      <th>district_code</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>party_code</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>last_means</th>\n",
       "      <th>bioname</th>\n",
       "      <th>...</th>\n",
       "      <th>nominate_dim2</th>\n",
       "      <th>nominate_log_likelihood</th>\n",
       "      <th>nominate_geo_mean_probability</th>\n",
       "      <th>nominate_number_of_votes</th>\n",
       "      <th>nominate_number_of_errors</th>\n",
       "      <th>conditional</th>\n",
       "      <th>nokken_poole_dim1</th>\n",
       "      <th>nokken_poole_dim2</th>\n",
       "      <th>account_id</th>\n",
       "      <th>mem_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116</td>\n",
       "      <td>House</td>\n",
       "      <td>21376</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>BYRNE, Bradley</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-101.0176</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>614</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.167</td>\n",
       "      <td>2253968388</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>116</td>\n",
       "      <td>House</td>\n",
       "      <td>21376</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>BYRNE, Bradley</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-101.0176</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>614</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.167</td>\n",
       "      <td>42481696</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress chamber  icpsr  state_icpsr  district_code state_abbrev  \\\n",
       "6       116   House  21376           41              1           AL   \n",
       "7       116   House  21376           41              1           AL   \n",
       "\n",
       "   party_code occupancy last_means         bioname  ... nominate_dim2  \\\n",
       "6         200                       BYRNE, Bradley  ...         0.244   \n",
       "7         200                       BYRNE, Bradley  ...         0.244   \n",
       "\n",
       "   nominate_log_likelihood  nominate_geo_mean_probability  \\\n",
       "6                -101.0176                         0.8483   \n",
       "7                -101.0176                         0.8483   \n",
       "\n",
       "   nominate_number_of_votes  nominate_number_of_errors  conditional  \\\n",
       "6                       614                         40          NaN   \n",
       "7                       614                         40          NaN   \n",
       "\n",
       "   nokken_poole_dim1 nokken_poole_dim2  account_id       mem_name  \n",
       "6              0.707             0.167  2253968388  Bradley Byrne  \n",
       "7              0.707             0.167    42481696  Bradley Byrne  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify multiple twitter accounts for congressperson\n",
    "twit_congress_df[twit_congress_df['mem_name']=='Bradley Byrne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>party_code</th>\n",
       "      <th>nominate_dim1</th>\n",
       "      <th>nominate_dim2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381152398</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69326168</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224294785</td>\n",
       "      <td>200</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69086398</td>\n",
       "      <td>200</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237299871</td>\n",
       "      <td>200</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>142332083</td>\n",
       "      <td>200</td>\n",
       "      <td>0.603</td>\n",
       "      <td>-0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>202206694</td>\n",
       "      <td>200</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>499268312</td>\n",
       "      <td>200</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>291756142</td>\n",
       "      <td>200</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1848942470</td>\n",
       "      <td>200</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1085 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account_id  party_code  nominate_dim1  nominate_dim2\n",
       "0      381152398         100         -0.391          0.402\n",
       "1       69326168         100         -0.391          0.402\n",
       "2      224294785         200          0.361          0.656\n",
       "3       69086398         200          0.361          0.656\n",
       "4      237299871         200          0.647         -0.446\n",
       "...          ...         ...            ...            ...\n",
       "1080   142332083         200          0.603         -0.288\n",
       "1081   202206694         200          0.539          0.237\n",
       "1082   499268312         200          0.539          0.237\n",
       "1083   291756142         200          0.544          0.192\n",
       "1084  1848942470         200          0.544          0.192\n",
       "\n",
       "[1085 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_congress_df[['account_id','party_code','nominate_dim1','nominate_dim2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.391"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_id_dict = twit_congress_df[['account_id','nominate_dim1','nominate_dim2','party_code']].set_index('account_id').to_dict()\n",
    "twit_id_dict['nominate_dim1'][69326168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training day consists of 50850.0 tweets.\n"
     ]
    }
   ],
   "source": [
    "# Specify dates for training data\n",
    "dates = pd.date_range(start='4/1/2020', end='4/30/2020')\n",
    "dates = [str(date)[0:10] for date in dates]\n",
    "\n",
    "# Specify number of samples per day per party\n",
    "date_samples = 1130\n",
    "print('Training day consists of '+str(2*date_samples*0.75*len(dates))+' tweets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01\n",
      "2020-04-02\n",
      "2020-04-03\n",
      "2020-04-04\n",
      "2020-04-05\n",
      "2020-04-06\n",
      "2020-04-07\n",
      "2020-04-08\n",
      "2020-04-09\n",
      "2020-04-10\n",
      "2020-04-11\n",
      "2020-04-12\n",
      "2020-04-13\n",
      "2020-04-14\n",
      "2020-04-15\n",
      "2020-04-16\n",
      "2020-04-17\n",
      "2020-04-18\n",
      "2020-04-19\n",
      "2020-04-20\n",
      "2020-04-21\n",
      "2020-04-22\n",
      "2020-04-23\n",
      "2020-04-24\n",
      "2020-04-25\n",
      "2020-04-26\n",
      "2020-04-27\n",
      "2020-04-28\n",
      "2020-04-29\n",
      "2020-04-30\n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe\n",
    "train_df = pd.DataFrame(columns=['text','nominate_dim1'])\n",
    "\n",
    "for date in dates:\n",
    "    date_str = date\n",
    "    example_tweets = pd.read_json(\"mediabias_main/congresstweets/data/\"+date_str+\".json\")\n",
    "    example_tweets[\"nominate_dim1\"] = example_tweets[\"user_id\"]\n",
    "    example_tweets[\"party_code\"] = example_tweets[\"user_id\"]\n",
    "    example_tweets = example_tweets.replace({\"nominate_dim1\":twit_id_dict['nominate_dim1']})\n",
    "    example_tweets = example_tweets.replace({\"party_code\":twit_id_dict['party_code']})\n",
    "    date_train_data = example_tweets[(example_tweets['party_code']!=100)|(example_tweets['party_code']!=200)][['text','party_code','nominate_dim1']]\n",
    "    # Rearrange rows\n",
    "    date_train_data = date_train_data.sample(frac=1)\n",
    "    date_train_data_R=date_train_data[date_train_data['party_code']==200].head(date_samples)\n",
    "    date_train_data_D=date_train_data[date_train_data['party_code']==100].head(date_samples)\n",
    "    # Remove stop words and fix party code\n",
    "    date_train_data = clean_tweets(date_train_data_D.append(date_train_data_R, ignore_index=True))\n",
    "    date_train_data = date_train_data[['text','nominate_dim1']]\n",
    "    #if date == date[0]:\n",
    "    #    train_df = date_train_data\n",
    "    #else:\n",
    "    train_df = train_df.append(date_train_data)#, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization - mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from joblib import dump, load # used for saving and loading sklearn objects\n",
    "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices\n",
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system(\"mkdir data_preprocessors\")\n",
    "system(\"mkdir vectorized_data\")\n",
    "\n",
    "# Unigram Counts\n",
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_vectorizer.fit(train_df['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_preprocessors/unigram_vectorizer-nom-mixed.joblib']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(unigram_vectorizer, 'data_preprocessors/unigram_vectorizer-nom-mixed.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram_vectorizer = load('data_preprocessors/unigram_vectorizer.joblib')\n",
    "\n",
    "X_train_unigram = unigram_vectorizer.transform(train_df['text'].values)\n",
    "save_npz('vectorized_data/X_train_unigram-nom-mixed.npz', X_train_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_preprocessors/unigram_tf_idf_transformer-non-mixed.joblib']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unigram Tf-Idf\n",
    "\n",
    "unigram_tf_idf_transformer = TfidfTransformer()\n",
    "unigram_tf_idf_transformer.fit(X_train_unigram)\n",
    "\n",
    "dump(unigram_tf_idf_transformer, 'data_preprocessors/unigram_tf_idf_transformer-non-mixed.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)\n",
    "\n",
    "save_npz('vectorized_data/X_train_unigram_tf_idf-non-mixed.npz', X_train_unigram_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_preprocessors/bigram_vectorizer-non-mixed.joblib']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigram Counts\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "bigram_vectorizer.fit(train_df['text'].values)\n",
    "\n",
    "dump(bigram_vectorizer, 'data_preprocessors/bigram_vectorizer-non-mixed.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bigram = bigram_vectorizer.transform(train_df['text'].values)\n",
    "\n",
    "save_npz('vectorized_data/X_train_bigram-non-mixed.npz', X_train_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_preprocessors/bigram_tf_idf_transformer-non-mixed.joblib']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tf_idf_transformer = TfidfTransformer()\n",
    "bigram_tf_idf_transformer.fit(X_train_bigram)\n",
    "\n",
    "dump(bigram_tf_idf_transformer, 'data_preprocessors/bigram_tf_idf_transformer-non-mixed.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\n",
    "\n",
    "save_npz('vectorized_data/X_train_bigram_tf_idf-non-mixed.npz', X_train_bigram_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDRegressor - Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, train_size=0.75\n",
    "    )\n",
    "\n",
    "    clf = SGDRegressor(max_iter=2000, tol=1e-5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')\n",
    "\n",
    "y_train = train_df['nominate_dim1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts\n",
      "Train score: 0.79 ; Validation score: 0.52\n",
      "\n",
      "Unigram Tf-Idf\n",
      "Train score: 0.53 ; Validation score: 0.46\n",
      "\n",
      "Bigram Counts\n",
      "Train score: 0.95 ; Validation score: 0.57\n",
      "\n",
      "Bigram Tf-Idf\n",
      "Train score: 0.53 ; Validation score: 0.41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
    "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
    "train_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\n",
    "train_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate by party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training day consists of 25425.0 tweets.\n"
     ]
    }
   ],
   "source": [
    "# Specify dates for training data\n",
    "dates = pd.date_range(start='4/1/2020', end='4/30/2020')\n",
    "dates = [str(date)[0:10] for date in dates]\n",
    "\n",
    "# Specify number of samples per day per party\n",
    "date_samples = 1130\n",
    "print('Training day consists of '+str(date_samples*0.75*len(dates))+' tweets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01\n",
      "2020-04-02\n",
      "2020-04-03\n",
      "2020-04-04\n",
      "2020-04-05\n",
      "2020-04-06\n",
      "2020-04-07\n",
      "2020-04-08\n",
      "2020-04-09\n",
      "2020-04-10\n",
      "2020-04-11\n",
      "2020-04-12\n",
      "2020-04-13\n",
      "2020-04-14\n",
      "2020-04-15\n",
      "2020-04-16\n",
      "2020-04-17\n",
      "2020-04-18\n",
      "2020-04-19\n",
      "2020-04-20\n",
      "2020-04-21\n",
      "2020-04-22\n",
      "2020-04-23\n",
      "2020-04-24\n",
      "2020-04-25\n",
      "2020-04-26\n",
      "2020-04-27\n",
      "2020-04-28\n",
      "2020-04-29\n",
      "2020-04-30\n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe\n",
    "R_train_df = pd.DataFrame(columns=['text','nominate_dim1'])\n",
    "D_train_df = pd.DataFrame(columns=['text','nominate_dim1'])\n",
    "\n",
    "for date in dates:\n",
    "    date_str = date\n",
    "    example_tweets = pd.read_json(\"mediabias_main/congresstweets/data/\"+date_str+\".json\")\n",
    "    example_tweets[\"nominate_dim1\"] = example_tweets[\"user_id\"]\n",
    "    example_tweets[\"party_code\"] = example_tweets[\"user_id\"]\n",
    "    example_tweets = example_tweets.replace({\"nominate_dim1\":twit_id_dict['nominate_dim1']})\n",
    "    example_tweets = example_tweets.replace({\"party_code\":twit_id_dict['party_code']})\n",
    "    date_train_data = example_tweets[(example_tweets['party_code']!=100)][['text','party_code','nominate_dim1']]\n",
    "    date_train_data = date_train_data[['text','nominate_dim1']]\n",
    "    R_train_df = train_df.append(date_train_data)#, ignore_index=True)\n",
    "    \n",
    "    date_train_data = example_tweets[(example_tweets['party_code']!=200)][['text','party_code','nominate_dim1']]\n",
    "    date_train_data = date_train_data[['text','nominate_dim1']]\n",
    "    D_train_df = train_df.append(date_train_data)#, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train_df = R_train_df.reset_index(drop=True)\n",
    "D_train_df = D_train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_preprocessors/unigram_vectorizer-nom-D.joblib']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unigram Counts\n",
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_vectorizer.fit(R_train_df['text'].values)\n",
    "dump(unigram_vectorizer, 'data_preprocessors/unigram_vectorizer-nom-R.joblib')\n",
    "unigram_vectorizer.fit(D_train_df['text'].values)\n",
    "dump(unigram_vectorizer, 'data_preprocessors/unigram_vectorizer-nom-D.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_R_train_unigram = unigram_vectorizer.transform(R_train_df['text'].values)\n",
    "save_npz('vectorized_data/X_train_unigram-nom-mixed.npz', X_R_train_unigram)\n",
    "\n",
    "X_D_train_unigram = unigram_vectorizer.transform(D_train_df['text'].values)\n",
    "save_npz('vectorized_data/X_train_unigram-nom-mixed.npz', X_D_train_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_text = request.form['text']\n",
    "# fun_input = list_tostring(word_tokenize(in_text))\n",
    "\n",
    "# X_pred = bigram_vectorizer.transform([fun_input])\n",
    "# X_pred = bigram_tf_idf_transformer.transform(X_pred)\n",
    "# sgd_classifier = load('classifiers/sgd_classifier.joblib')\n",
    "# result = sgd_classifier.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
